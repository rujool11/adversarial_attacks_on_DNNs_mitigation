{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C37bmHu6YXyE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8EADEKaLYdW2"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 96  # Upscale CIFAR-10 images (32x32) to 96x96 for MobileNetV2\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "84BsFVvsYlYG"
   },
   "outputs": [],
   "source": [
    "def resize_and_preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = preprocess_input(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAXP4UXlYnj0",
    "outputId": "58e380aa-37a3-426d-b1fa-7737daf9478f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 test dataset\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ew60zMJTYpq6"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"adversarially_trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_gKhMjdlY2eo"
   },
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(resize_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dawmInLuYvty",
    "outputId": "4e6e46f4-3fa1-46a7-b0f8-56f633f76430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9865 - loss: 0.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04580976814031601, 0.9868999719619751)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IzZn9UXBYxai"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def batched_fgsm_attack(images, labels, epsilon=0.01):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        predictions = model(images, training=False)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "    gradients = tape.gradient(loss, images)\n",
    "    adv_images = images + epsilon * tf.sign(gradients)\n",
    "    adv_images = tf.clip_by_value(adv_images, -1, 1)\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "se9IsU34Y_dp"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def batched_pgd_attack(images, labels, epsilon=0.01, alpha=0.005, num_iter=10):\n",
    "    adv_images = tf.identity(images)\n",
    "\n",
    "    for _ in tf.range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(adv_images)\n",
    "            predictions = model(adv_images, training=False)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "        gradients = tape.gradient(loss, adv_images)\n",
    "        adv_images = adv_images + alpha * tf.sign(gradients)\n",
    "\n",
    "        # Project perturbation\n",
    "        perturbation = tf.clip_by_value(adv_images - images, -epsilon, epsilon)\n",
    "        adv_images = tf.clip_by_value(images + perturbation, -1, 1)\n",
    "\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y5xqGaTVZBQE"
   },
   "outputs": [],
   "source": [
    "def deepfool_attack(image, num_classes=10, overshoot=0.0000001, max_iter=1):\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    perturbed_image = tf.identity(image)\n",
    "\n",
    "    # Get original prediction and label\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(perturbed_image)\n",
    "        logits = model(tf.expand_dims(perturbed_image, axis=0))[0]\n",
    "    orig_label = tf.argmax(logits)\n",
    "\n",
    "    r_tot = tf.zeros_like(image)\n",
    "    i = 0\n",
    "\n",
    "    while i < max_iter:\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(perturbed_image)\n",
    "            logits = model(tf.expand_dims(perturbed_image, axis=0))[0]\n",
    "\n",
    "        current_label = tf.argmax(logits)\n",
    "        if current_label != orig_label:\n",
    "            break\n",
    "\n",
    "        # Compute gradients for all class logits\n",
    "        gradients = []\n",
    "        for k in range(num_classes):\n",
    "            with tf.GradientTape() as tape2:\n",
    "                tape2.watch(perturbed_image)\n",
    "                logit_k = model(tf.expand_dims(perturbed_image, axis=0))[0, k]\n",
    "            grad_k = tape2.gradient(logit_k, perturbed_image)\n",
    "            gradients.append(grad_k)\n",
    "        gradients = tf.stack(gradients)\n",
    "\n",
    "        # Compute minimal perturbation\n",
    "        f_orig = logits[orig_label]\n",
    "        perturbs = []\n",
    "        for k in range(num_classes):\n",
    "            if k == orig_label:\n",
    "                continue\n",
    "            w_k = gradients[k] - gradients[orig_label]\n",
    "            f_k = logits[k] - f_orig\n",
    "            norm_w = tf.norm(tf.reshape(w_k, [-1])) + 1e-8\n",
    "            pert_k = tf.abs(f_k) / norm_w\n",
    "            perturbs.append((pert_k, w_k))\n",
    "\n",
    "        # Choose the closest decision boundary\n",
    "        perturbs.sort(key=lambda x: x[0])\n",
    "        pert_k, w_k = perturbs[0]\n",
    "\n",
    "        # Compute minimal directional perturbation (no sign scaling)\n",
    "        r_i = (pert_k * w_k) / (tf.norm(w_k) + 1e-8)\n",
    "        r_tot += r_i\n",
    "\n",
    "        # Apply accumulated perturbation with small overshoot\n",
    "        perturbed_image = image + (1 + overshoot) * r_tot\n",
    "        perturbed_image = tf.clip_by_value(perturbed_image, -1, 1)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Fmx3ANupZDRH"
   },
   "outputs": [],
   "source": [
    "def get_test_dataset():\n",
    "    # Load CIFAR-10 test dataset and preprocess\n",
    "    (_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    y_test = np.squeeze(y_test)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    ds = ds.map(resize_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ehPuYSmwZFr0"
   },
   "outputs": [],
   "source": [
    "clean_ds = get_test_dataset()\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-Tk7dBWVZI-u"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_dataset_fast(dataset, attack_fn, attack_name=\"FGSM\"):\n",
    "    adv_images_all = []\n",
    "    adv_labels_all = []\n",
    "\n",
    "    print(f\"\\nBuilding {attack_name} dataset...\")\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        adv_images = attack_fn(images, labels)\n",
    "        adv_images_all.append(adv_images)\n",
    "        adv_labels_all.append(labels)\n",
    "\n",
    "    adv_images_all = tf.concat(adv_images_all, axis=0)\n",
    "    adv_labels_all = tf.concat(adv_labels_all, axis=0)\n",
    "\n",
    "    adv_ds = tf.data.Dataset.from_tensor_slices((adv_images_all, adv_labels_all))\n",
    "    return adv_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3RnZebz1ZJdB"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_dataset_deepfool(attack_fn, name=\"DeepFool\", max_samples=500, num_classes=10):\n",
    "    adv_images = []\n",
    "    adv_labels = []\n",
    "\n",
    "    print(f\"\\nGenerating {name} adversarial dataset (max {max_samples} samples)...\")\n",
    "    sample_count = 0\n",
    "\n",
    "    for images, labels in clean_ds:\n",
    "        for img, label in zip(images, labels):\n",
    "            # Pass a fixed number of classes instead of the label value.\n",
    "            adv_img = attack_fn(img, num_classes)\n",
    "            adv_images.append(adv_img.numpy())\n",
    "            adv_labels.append(int(label.numpy()))\n",
    "            sample_count += 1\n",
    "\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "\n",
    "    adv_images = np.array(adv_images)\n",
    "    adv_labels = np.array(adv_labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((adv_images, adv_labels))\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_nKUmKkoZNNk"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(dataset, name=\"Dataset\"):\n",
    "    y_true, y_pred = [], []\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        preds = model(batch_images, training=False)\n",
    "        loss = loss_fn(batch_labels, preds).numpy()\n",
    "        pred_classes = tf.argmax(preds, axis=1).numpy()\n",
    "        y_true.extend(batch_labels.numpy())\n",
    "        y_pred.extend(pred_classes)\n",
    "        total_loss += loss * len(batch_labels)\n",
    "        total_samples += len(batch_labels)\n",
    "\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    avg_loss = total_loss / total_samples\n",
    "    correct = sum(np.array(y_true) == np.array(y_pred))\n",
    "    incorrect = total_samples - correct\n",
    "\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"  Total Samples: {total_samples}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Correct Predictions: {correct}\")\n",
    "    print(f\"  Incorrect Predictions: {incorrect}\")\n",
    "    return accuracy, avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snqk2AaJZPxF",
    "outputId": "051e3013-7e23-4761-f335-089fd2a6799e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building FGSM dataset...\n",
      "\n",
      "Building PGD dataset...\n",
      "\n",
      "Generating DeepFool adversarial dataset (max 200 samples)...\n"
     ]
    }
   ],
   "source": [
    "fgsm_ds = build_adversarial_dataset_fast(clean_ds, lambda x, y: batched_fgsm_attack(x, y, epsilon=0.01), attack_name=\"FGSM\")\n",
    "pgd_ds = build_adversarial_dataset_fast(clean_ds, lambda x, y: batched_pgd_attack(x, y, epsilon=0.01, alpha=0.005, num_iter=10), attack_name=\"PGD\")\n",
    "deepfool_ds = build_adversarial_dataset_deepfool(deepfool_attack, name=\"DeepFool\", max_samples=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uD3-X01cgtsp"
   },
   "outputs": [],
   "source": [
    "def load_original_model():\n",
    "    return tf.keras.models.load_model(\"adversarially_trained_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tfcfFyrWZTMX"
   },
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(size=3, sigma=1.0):\n",
    "    \"\"\"Creates a 2D Gaussian kernel.\"\"\"\n",
    "    x = tf.range(-size // 2 + 1, size // 2 + 1, dtype=tf.float32)\n",
    "    x = tf.exp(-(x**2) / (2 * sigma**2))\n",
    "    kernel_1d = x / tf.reduce_sum(x)\n",
    "    kernel_2d = tf.tensordot(kernel_1d, kernel_1d, axes=0)\n",
    "    kernel_2d = kernel_2d / tf.reduce_sum(kernel_2d)\n",
    "    return kernel_2d[:, :, tf.newaxis, tf.newaxis]  # Shape: (H, W, in_channels=1, out_channels=1)\n",
    "\n",
    "def apply_gaussian_blur(x, sigma):\n",
    "    \"\"\"Applies Gaussian blur using depthwise convolution.\"\"\"\n",
    "    kernel = get_gaussian_kernel(size=3, sigma=sigma)\n",
    "    channels = tf.shape(x)[-1]\n",
    "    kernel = tf.tile(kernel, [1, 1, channels, 1])  # Make kernel channel-wise\n",
    "    x = tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jd2opRiUZVZh"
   },
   "outputs": [],
   "source": [
    "def inference_input_transformation(\n",
    "    x,\n",
    "    apply_bitdepth=True,\n",
    "    bits=4,\n",
    "    apply_noise=True,\n",
    "    noise_std=0.05,\n",
    "    apply_jpeg=True,\n",
    "    jpeg_quality=75,\n",
    "    apply_blur=True,\n",
    "    blur_sigma=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply input transformations: quantization, noise, JPEG compression, and blur.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor in [0,1].\n",
    "    \"\"\"\n",
    "    if apply_bitdepth:\n",
    "        levels = 2 ** bits\n",
    "        x = tf.round(x * (levels - 1)) / (levels - 1)\n",
    "\n",
    "    if apply_noise:\n",
    "        noise = tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std, dtype=x.dtype)\n",
    "        x = x + noise\n",
    "\n",
    "    if apply_jpeg:\n",
    "        def jpeg_fn(img):\n",
    "            img_uint8 = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "            encoded = tf.io.encode_jpeg(img_uint8, quality=jpeg_quality)\n",
    "            decoded = tf.io.decode_jpeg(encoded)\n",
    "            return tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "        x = tf.map_fn(jpeg_fn, x)\n",
    "\n",
    "    if apply_blur:\n",
    "        x = apply_gaussian_blur(x, sigma=blur_sigma)\n",
    "\n",
    "    x = tf.clip_by_value(x, 0.0, 1.0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Onugr9PrZe6F"
   },
   "outputs": [],
   "source": [
    "class TransformedModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model,\n",
    "        apply_bitdepth=True,\n",
    "        bits=4,\n",
    "        apply_noise=True,\n",
    "        noise_std=0.05,\n",
    "        apply_jpeg=True,\n",
    "        jpeg_quality=75,\n",
    "        apply_blur=True,\n",
    "        blur_sigma=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.apply_bitdepth = apply_bitdepth\n",
    "        self.bits = bits\n",
    "        self.apply_noise = apply_noise\n",
    "        self.noise_std = noise_std\n",
    "        self.apply_jpeg = apply_jpeg\n",
    "        self.jpeg_quality = jpeg_quality\n",
    "        self.apply_blur = apply_blur\n",
    "        self.blur_sigma = blur_sigma\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Convert from [-1, 1] to [0, 1] before transformation\n",
    "        inputs = (inputs + 1.0) / 2.0\n",
    "\n",
    "        transformed = inference_input_transformation(\n",
    "            inputs,\n",
    "            apply_bitdepth=self.apply_bitdepth,\n",
    "            bits=self.bits,\n",
    "            apply_noise=self.apply_noise,\n",
    "            noise_std=self.noise_std,\n",
    "            apply_jpeg=self.apply_jpeg,\n",
    "            jpeg_quality=self.jpeg_quality,\n",
    "            apply_blur=self.apply_blur,\n",
    "            blur_sigma=self.blur_sigma\n",
    "        )\n",
    "\n",
    "        # Convert back to [-1, 1] for model input\n",
    "        transformed = transformed * 2.0 - 1.0\n",
    "        return self.base_model(transformed, training=training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pAA8VRJDZjVq"
   },
   "outputs": [],
   "source": [
    "# all transformations applied\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=True, bits=4,\n",
    "    apply_noise=True, noise_std=0.05,\n",
    "    apply_jpeg=True, jpeg_quality=75,\n",
    "    apply_blur=True, blur_sigma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLRccGvLcIRM",
    "outputId": "32fbdad2-86db-496e-b96e-6304ece8d914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed_default Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4337\n",
      "  Loss: 2.2827\n",
      "  Correct Predictions: 4337\n",
      "  Incorrect Predictions: 5663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4337), np.float32(2.2826812))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l20wF1dZcIti",
    "outputId": "abc7e05f-223e-45c1-ebcc-ea68530c7ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_default Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4156\n",
      "  Loss: 2.3821\n",
      "  Correct Predictions: 4156\n",
      "  Incorrect Predictions: 5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4156), np.float32(2.3821476))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DkdNSThcMVy",
    "outputId": "d1e49503-5679-4e26-f7c9-b64d2469b327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_default Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4134\n",
      "  Loss: 2.3758\n",
      "  Correct Predictions: 4134\n",
      "  Incorrect Predictions: 5866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4134), np.float32(2.3758323))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8EdvYCsGUjn",
    "outputId": "353c9db6-c2ca-4cc4-892a-c406e9400d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_default Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.1650\n",
      "  Loss: 5.1539\n",
      "  Correct Predictions: 33\n",
      "  Incorrect Predictions: 167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.165), np.float32(5.1538787))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wVDMe1OmeMYZ"
   },
   "outputs": [],
   "source": [
    "# no bitdepth\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=False,  # Bitdepth reduction disabled\n",
    "    apply_noise=True, noise_std=0.05,\n",
    "    apply_jpeg=True, jpeg_quality=75,\n",
    "    apply_blur=True, blur_sigma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1XAqEvqe-X8",
    "outputId": "b63e4b40-d8f1-4a2f-a6b7-45c7e9afe32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed_no_bitdepth Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4913\n",
      "  Loss: 1.9947\n",
      "  Correct Predictions: 4913\n",
      "  Incorrect Predictions: 5087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4913), np.float32(1.9946779))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed_no_bitdepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLAUk7x9fGmy",
    "outputId": "78e186f2-b442-43d6-e3c3-8123cccb1c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_default_no_bitdepth Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4563\n",
      "  Loss: 2.1446\n",
      "  Correct Predictions: 4563\n",
      "  Incorrect Predictions: 5437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4563), np.float32(2.144608))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_default_no_bitdepth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykiOMMhtfWlD",
    "outputId": "0c49bb86-0b8d-4102-bb49-65b4f6e35e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_default_no_bitdepth Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4613\n",
      "  Loss: 2.1215\n",
      "  Correct Predictions: 4613\n",
      "  Incorrect Predictions: 5387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4613), np.float32(2.1214905))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_default_no_bitdepth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVZdTTUlfdPZ",
    "outputId": "0f1c7743-778b-4049-d589-e8d4ac1ed583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_no_bitdepth Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.1750\n",
      "  Loss: 5.0621\n",
      "  Correct Predictions: 35\n",
      "  Incorrect Predictions: 165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.175), np.float32(5.062115))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_no_bitdepth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "rugc8DjneZ8c"
   },
   "outputs": [],
   "source": [
    "# no noise\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=True, bits=4,\n",
    "    apply_noise=False,    # Noise addition disabled\n",
    "    apply_jpeg=True, jpeg_quality=75,\n",
    "    apply_blur=True, blur_sigma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzWn-v6te--9",
    "outputId": "5d7ff59d-2f43-4d3a-f8ac-d2f85b039322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed_no_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.9017\n",
      "  Loss: 0.2887\n",
      "  Correct Predictions: 9017\n",
      "  Incorrect Predictions: 983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9017), np.float32(0.28868285))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed_no_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqYvQjDifHeP",
    "outputId": "4a4361f5-02f2-45a0-f632-2edbaf7a06db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_no_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.7851\n",
      "  Loss: 0.7013\n",
      "  Correct Predictions: 7851\n",
      "  Incorrect Predictions: 2149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7851), np.float32(0.7012873))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_no_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0od18Yl4fXxV",
    "outputId": "e9e9ff75-e777-44b0-c8a9-2ff2077cb2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_no_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.8125\n",
      "  Loss: 0.5893\n",
      "  Correct Predictions: 8125\n",
      "  Incorrect Predictions: 1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8125), np.float32(0.58929026))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_no_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bomCbl1Kfd_p",
    "outputId": "101af361-cf67-4fce-9019-5adfab96210d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_no_noise Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.3000\n",
      "  Loss: 4.1993\n",
      "  Correct Predictions: 60\n",
      "  Incorrect Predictions: 140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3), np.float32(4.1993437))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_no_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FuHvl7FzecG6"
   },
   "outputs": [],
   "source": [
    "# no jpeg compression\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=True, bits=4,\n",
    "    apply_noise=True, noise_std=0.05,\n",
    "    apply_jpeg=False,     # JPEG compression disabled\n",
    "    apply_blur=True, blur_sigma=0.5\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tybOj3pe_o8",
    "outputId": "f6eef5b7-236e-4db8-8b71-188c251fd30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed_no_jpeg Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.3874\n",
      "  Loss: 2.3156\n",
      "  Correct Predictions: 3874\n",
      "  Incorrect Predictions: 6126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3874), np.float32(2.3156402))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed_no_jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybapYK4LfIbj",
    "outputId": "bedee186-bc97-4818-97f5-e2596d2b0d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_no_jpeg Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.3612\n",
      "  Loss: 2.4278\n",
      "  Correct Predictions: 3612\n",
      "  Incorrect Predictions: 6388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3612), np.float32(2.4277833))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_no_jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L92vQ4wffYnm",
    "outputId": "9de6f9f3-a441-4e8a-b5c9-9b09c62c53d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_no_jpeg Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.3578\n",
      "  Loss: 2.4544\n",
      "  Correct Predictions: 3578\n",
      "  Incorrect Predictions: 6422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3578), np.float32(2.4544492))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_no_jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-JZrK8zffBi",
    "outputId": "9c357365-1eba-4599-ea74-bbb2fb53f5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_no_jpeg Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.1250\n",
      "  Loss: 5.6194\n",
      "  Correct Predictions: 25\n",
      "  Incorrect Predictions: 175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.125), np.float32(5.6193657))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_no_jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oQK8Fy3yejrO"
   },
   "outputs": [],
   "source": [
    "# no blur, higher jpeg quality\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=True, bits=4,\n",
    "    apply_noise=True, noise_std=0.05,\n",
    "    apply_jpeg=True, jpeg_quality=90,  # Higher JPEG quality\n",
    "    apply_blur=False,   # Blur disabled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVIzLLOZfASO",
    "outputId": "42d5ee82-960b-41e1-ddb2-b80d20912e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed__no_blur Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.2894\n",
      "  Loss: 2.9377\n",
      "  Correct Predictions: 2894\n",
      "  Incorrect Predictions: 7106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2894), np.float32(2.937708))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed__no_blur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P93CDwjfJI0",
    "outputId": "643a69dc-d3eb-44da-b6fc-8fc318dc9223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_no_blur Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.2784\n",
      "  Loss: 2.9834\n",
      "  Correct Predictions: 2784\n",
      "  Incorrect Predictions: 7216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2784), np.float32(2.9833708))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_no_blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABKKW8xwfZcb",
    "outputId": "ffbe4366-9ceb-4b8d-d4da-8dd2d4d56ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_no_blur Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.2785\n",
      "  Loss: 2.9884\n",
      "  Correct Predictions: 2785\n",
      "  Incorrect Predictions: 7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2785), np.float32(2.9884486))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_no_blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnPqgUi3ffup",
    "outputId": "c7765088-0bc8-45bb-af10-506bb487fd88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_no_blur Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.0950\n",
      "  Loss: 5.6535\n",
      "  Correct Predictions: 19\n",
      "  Incorrect Predictions: 181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.095), np.float32(5.6534715))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_no_blur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "w_sVetiHeuug"
   },
   "outputs": [],
   "source": [
    "# no noise and no bitdepth\n",
    "model = TransformedModel(\n",
    "    load_original_model(),\n",
    "    apply_bitdepth=False, bits=4, # Disable bitdepth\n",
    "    apply_noise=False,    # Disable noise\n",
    "    noise_std=0.05,\n",
    "    apply_jpeg=True, jpeg_quality=75,\n",
    "    apply_blur=True,\n",
    "    blur_sigma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtnUArJpfA-2",
    "outputId": "908dd605-b276-440c-ff9f-c01d06828386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + Transformed_no_bitdepth_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.9428\n",
      "  Loss: 0.1624\n",
      "  Correct Predictions: 9428\n",
      "  Incorrect Predictions: 572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9428), np.float32(0.16239214))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + Transformed_no_bitdepth_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVOBB020fgde",
    "outputId": "8405ea44-c94f-4aae-f5e2-ed624635e26c"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed_no_bitdepth_noise Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.2650\n",
      "  Loss: 4.3098\n",
      "  Correct Predictions: 53\n",
      "  Incorrect Predictions: 147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.265), np.float32(4.3098006))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed_no_bitdepth_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxSUwN9bpDPx",
    "outputId": "39d4a971-7e07-4788-95c5-7fe53265e1e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed_no_bitdepth_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.7741\n",
      "  Loss: 0.6948\n",
      "  Correct Predictions: 7741\n",
      "  Incorrect Predictions: 2259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7741), np.float32(0.69478834))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed_no_bitdepth_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ph1UApCdpExd",
    "outputId": "135f1603-e1ee-42d3-e3ca-4ff736be6179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed_no_bitdepth_noise Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.8416\n",
      "  Loss: 0.4605\n",
      "  Correct Predictions: 8416\n",
      "  Incorrect Predictions: 1584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8416), np.float32(0.46049884))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed_no_bitdepth_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn4FWY5npGR0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
