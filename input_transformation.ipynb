{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7OjAt3k7dz-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9lCYPo47ilo"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 96  # Upscale CIFAR-10 images (32x32) to 96x96 for MobileNetV2\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neucto_67kWj"
   },
   "outputs": [],
   "source": [
    "def resize_and_preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = preprocess_input(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFgJO0fp718V",
    "outputId": "46b66916-c6a6-4c83-9826-95a3782e6f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 test dataset\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3ZQgJxC74G9"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVwOfqVV76Fx"
   },
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.map(resize_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLXNE2hx8EZa",
    "outputId": "3fd61970-5268-4f80-a4bf-d596ac9de1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.9132 - loss: 0.2790\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvpzQ8Mz8axT",
    "outputId": "b13b6a01-0230-42c4-e818-dfc54d23832a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2672818899154663, 0.9153000116348267)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukzT8sUH_NQW"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def batched_fgsm_attack(images, labels, epsilon=0.01):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        predictions = model(images, training=False)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "    gradients = tape.gradient(loss, images)\n",
    "    adv_images = images + epsilon * tf.sign(gradients)\n",
    "    adv_images = tf.clip_by_value(adv_images, -1, 1)\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZQCzLDw_Or9"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def batched_pgd_attack(images, labels, epsilon=0.01, alpha=0.005, num_iter=10):\n",
    "    adv_images = tf.identity(images)\n",
    "\n",
    "    for _ in tf.range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(adv_images)\n",
    "            predictions = model(adv_images, training=False)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "        gradients = tape.gradient(loss, adv_images)\n",
    "        adv_images = adv_images + alpha * tf.sign(gradients)\n",
    "\n",
    "        # Project perturbation\n",
    "        perturbation = tf.clip_by_value(adv_images - images, -epsilon, epsilon)\n",
    "        adv_images = tf.clip_by_value(images + perturbation, -1, 1)\n",
    "\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WavHpilK8tJM"
   },
   "outputs": [],
   "source": [
    "def deepfool_attack(image, num_classes=10, overshoot=0.0000001, max_iter=1):\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    perturbed_image = tf.identity(image)\n",
    "\n",
    "    # Get original prediction and label\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(perturbed_image)\n",
    "        logits = model(tf.expand_dims(perturbed_image, axis=0))[0]\n",
    "    orig_label = tf.argmax(logits)\n",
    "\n",
    "    r_tot = tf.zeros_like(image)\n",
    "    i = 0\n",
    "\n",
    "    while i < max_iter:\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(perturbed_image)\n",
    "            logits = model(tf.expand_dims(perturbed_image, axis=0))[0]\n",
    "\n",
    "        current_label = tf.argmax(logits)\n",
    "        if current_label != orig_label:\n",
    "            break\n",
    "\n",
    "        # Compute gradients for all class logits\n",
    "        gradients = []\n",
    "        for k in range(num_classes):\n",
    "            with tf.GradientTape() as tape2:\n",
    "                tape2.watch(perturbed_image)\n",
    "                logit_k = model(tf.expand_dims(perturbed_image, axis=0))[0, k]\n",
    "            grad_k = tape2.gradient(logit_k, perturbed_image)\n",
    "            gradients.append(grad_k)\n",
    "        gradients = tf.stack(gradients)\n",
    "\n",
    "        # Compute minimal perturbation\n",
    "        f_orig = logits[orig_label]\n",
    "        perturbs = []\n",
    "        for k in range(num_classes):\n",
    "            if k == orig_label:\n",
    "                continue\n",
    "            w_k = gradients[k] - gradients[orig_label]\n",
    "            f_k = logits[k] - f_orig\n",
    "            norm_w = tf.norm(tf.reshape(w_k, [-1])) + 1e-8\n",
    "            pert_k = tf.abs(f_k) / norm_w\n",
    "            perturbs.append((pert_k, w_k))\n",
    "\n",
    "        # Choose the closest decision boundary\n",
    "        perturbs.sort(key=lambda x: x[0])\n",
    "        pert_k, w_k = perturbs[0]\n",
    "\n",
    "        # Compute minimal directional perturbation (no sign scaling)\n",
    "        r_i = (pert_k * w_k) / (tf.norm(w_k) + 1e-8)\n",
    "        r_tot += r_i\n",
    "\n",
    "        # Apply accumulated perturbation with small overshoot\n",
    "        perturbed_image = image + (1 + overshoot) * r_tot\n",
    "        perturbed_image = tf.clip_by_value(perturbed_image, -1, 1)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfxOuqcJWUNe"
   },
   "outputs": [],
   "source": [
    "def get_test_dataset():\n",
    "    # Load CIFAR-10 test dataset and preprocess\n",
    "    (_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    y_test = np.squeeze(y_test)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    ds = ds.map(resize_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW9NcWS1_ChF"
   },
   "outputs": [],
   "source": [
    "clean_ds = get_test_dataset()\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80ODgq-P8fdY"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_dataset_fast(dataset, attack_fn, attack_name=\"FGSM\"):\n",
    "    adv_images_all = []\n",
    "    adv_labels_all = []\n",
    "\n",
    "    print(f\"\\nBuilding {attack_name} dataset...\")\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        adv_images = attack_fn(images, labels)\n",
    "        adv_images_all.append(adv_images)\n",
    "        adv_labels_all.append(labels)\n",
    "\n",
    "    adv_images_all = tf.concat(adv_images_all, axis=0)\n",
    "    adv_labels_all = tf.concat(adv_labels_all, axis=0)\n",
    "\n",
    "    adv_ds = tf.data.Dataset.from_tensor_slices((adv_images_all, adv_labels_all))\n",
    "    return adv_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgSvSuAs84Xq"
   },
   "outputs": [],
   "source": [
    "def build_adversarial_dataset_deepfool(attack_fn, name=\"DeepFool\", max_samples=500, num_classes=10):\n",
    "    adv_images = []\n",
    "    adv_labels = []\n",
    "\n",
    "    print(f\"\\nGenerating {name} adversarial dataset (max {max_samples} samples)...\")\n",
    "    sample_count = 0\n",
    "\n",
    "    for images, labels in clean_ds:\n",
    "        for img, label in zip(images, labels):\n",
    "            # Pass a fixed number of classes instead of the label value.\n",
    "            adv_img = attack_fn(img, num_classes)\n",
    "            adv_images.append(adv_img.numpy())\n",
    "            adv_labels.append(int(label.numpy()))\n",
    "            sample_count += 1\n",
    "\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "\n",
    "    adv_images = np.array(adv_images)\n",
    "    adv_labels = np.array(adv_labels)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((adv_images, adv_labels))\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpZ-BRn29b9Q"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(dataset, name=\"Dataset\"):\n",
    "    y_true, y_pred = [], []\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        preds = model(batch_images, training=False)\n",
    "        loss = loss_fn(batch_labels, preds).numpy()\n",
    "        pred_classes = tf.argmax(preds, axis=1).numpy()\n",
    "        y_true.extend(batch_labels.numpy())\n",
    "        y_pred.extend(pred_classes)\n",
    "        total_loss += loss * len(batch_labels)\n",
    "        total_samples += len(batch_labels)\n",
    "\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    avg_loss = total_loss / total_samples\n",
    "    correct = sum(np.array(y_true) == np.array(y_pred))\n",
    "    incorrect = total_samples - correct\n",
    "\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"  Total Samples: {total_samples}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Correct Predictions: {correct}\")\n",
    "    print(f\"  Incorrect Predictions: {incorrect}\")\n",
    "    return accuracy, avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JsoMgov87Dd",
    "outputId": "47c5dda7-4494-484c-9daf-72b1dda1f823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building FGSM dataset...\n",
      "\n",
      "Building PGD dataset...\n"
     ]
    }
   ],
   "source": [
    "fgsm_ds = build_adversarial_dataset_fast(clean_ds, lambda x, y: batched_fgsm_attack(x, y, epsilon=0.01), attack_name=\"FGSM\")\n",
    "pgd_ds = build_adversarial_dataset_fast(clean_ds, lambda x, y: batched_pgd_attack(x, y, epsilon=0.01, alpha=0.005, num_iter=10), attack_name=\"PGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4s8JZLSS87fd",
    "outputId": "38e082b4-cdb3-4ca4-f2ed-a644af41317a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.1820\n",
      "  Loss: 5.1916\n",
      "  Correct Predictions: 1820\n",
      "  Incorrect Predictions: 8180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.182), np.float32(5.191604))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FB6ldwKr89wy",
    "outputId": "1f14642f-df16-4a17-93f2-2997ee14da13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.0000\n",
      "  Loss: 22.0664\n",
      "  Correct Predictions: 0\n",
      "  Incorrect Predictions: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float32(22.066427))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_J3QW-rV9CSh",
    "outputId": "b455ba05-d51f-4cd7-9c2e-7dc8b19ea5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating DeepFool adversarial dataset (max 200 samples)...\n",
      "\n",
      "DeepFool Attack Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.1500\n",
      "  Loss: 5.1534\n",
      "  Correct Predictions: 30\n",
      "  Incorrect Predictions: 170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.15), np.float32(5.153436))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfool_ds = build_adversarial_dataset_deepfool(deepfool_attack, name=\"DeepFool\", max_samples=200)\n",
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool Attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5smZRo3KdjP"
   },
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(size=3, sigma=1.0):\n",
    "    \"\"\"Creates a 2D Gaussian kernel.\"\"\"\n",
    "    x = tf.range(-size // 2 + 1, size // 2 + 1, dtype=tf.float32)\n",
    "    x = tf.exp(-(x**2) / (2 * sigma**2))\n",
    "    kernel_1d = x / tf.reduce_sum(x)\n",
    "    kernel_2d = tf.tensordot(kernel_1d, kernel_1d, axes=0)\n",
    "    kernel_2d = kernel_2d / tf.reduce_sum(kernel_2d)\n",
    "    return kernel_2d[:, :, tf.newaxis, tf.newaxis]  # Shape: (H, W, in_channels=1, out_channels=1)\n",
    "\n",
    "def apply_gaussian_blur(x, sigma):\n",
    "    \"\"\"Applies Gaussian blur using depthwise convolution.\"\"\"\n",
    "    kernel = get_gaussian_kernel(size=3, sigma=sigma)\n",
    "    channels = tf.shape(x)[-1]\n",
    "    kernel = tf.tile(kernel, [1, 1, channels, 1])  # Make kernel channel-wise\n",
    "    x = tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rS3fYXlZ_tqI"
   },
   "outputs": [],
   "source": [
    "def inference_input_transformation(\n",
    "    x,\n",
    "    apply_bitdepth=True,\n",
    "    bits=4,\n",
    "    apply_noise=True,\n",
    "    noise_std=0.05,\n",
    "    apply_jpeg=True,\n",
    "    jpeg_quality=75,\n",
    "    apply_blur=True,\n",
    "    blur_sigma=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply input transformations: quantization, noise, JPEG compression, and blur.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor in [0,1].\n",
    "    \"\"\"\n",
    "    if apply_bitdepth:\n",
    "        levels = 2 ** bits\n",
    "        x = tf.round(x * (levels - 1)) / (levels - 1)\n",
    "\n",
    "    if apply_noise:\n",
    "        noise = tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std, dtype=x.dtype)\n",
    "        x = x + noise\n",
    "\n",
    "    if apply_jpeg:\n",
    "        def jpeg_fn(img):\n",
    "            img_uint8 = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "            encoded = tf.io.encode_jpeg(img_uint8, quality=jpeg_quality)\n",
    "            decoded = tf.io.decode_jpeg(encoded)\n",
    "            return tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "        x = tf.map_fn(jpeg_fn, x)\n",
    "\n",
    "    if apply_blur:\n",
    "        x = apply_gaussian_blur(x, sigma=blur_sigma)\n",
    "\n",
    "    x = tf.clip_by_value(x, 0.0, 1.0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlqdREcvAFuM"
   },
   "outputs": [],
   "source": [
    "class TransformedModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model,\n",
    "        apply_bitdepth=True,\n",
    "        bits=4,\n",
    "        apply_noise=True,\n",
    "        noise_std=0.05,\n",
    "        apply_jpeg=True,\n",
    "        jpeg_quality=75,\n",
    "        apply_blur=True,\n",
    "        blur_sigma=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.apply_bitdepth = apply_bitdepth\n",
    "        self.bits = bits\n",
    "        self.apply_noise = apply_noise\n",
    "        self.noise_std = noise_std\n",
    "        self.apply_jpeg = apply_jpeg\n",
    "        self.jpeg_quality = jpeg_quality\n",
    "        self.apply_blur = apply_blur\n",
    "        self.blur_sigma = blur_sigma\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Convert from [-1, 1] to [0, 1] before transformation\n",
    "        inputs = (inputs + 1.0) / 2.0\n",
    "\n",
    "        transformed = inference_input_transformation(\n",
    "            inputs,\n",
    "            apply_bitdepth=self.apply_bitdepth,\n",
    "            bits=self.bits,\n",
    "            apply_noise=self.apply_noise,\n",
    "            noise_std=self.noise_std,\n",
    "            apply_jpeg=self.apply_jpeg,\n",
    "            jpeg_quality=self.jpeg_quality,\n",
    "            apply_blur=self.apply_blur,\n",
    "            blur_sigma=self.blur_sigma\n",
    "        )\n",
    "\n",
    "        # Convert back to [-1, 1] for model input\n",
    "        transformed = transformed * 2.0 - 1.0\n",
    "        return self.base_model(transformed, training=training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOfHq3iSF_85"
   },
   "outputs": [],
   "source": [
    "model = TransformedModel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGLhFsiqJsFP",
    "outputId": "3392679e-5448-4719-d3d4-744e285df00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean + transformed Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.4095\n",
      "  Loss: 2.4089\n",
      "  Correct Predictions: 4095\n",
      "  Incorrect Predictions: 5905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4095), np.float32(2.4088583))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(clean_ds, name='Clean + transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3L6we3RnGOGK",
    "outputId": "2dc1ff47-73b0-4499-ed46-17b9483e0d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FGSM + Transformed Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.3898\n",
      "  Loss: 2.5223\n",
      "  Correct Predictions: 3898\n",
      "  Incorrect Predictions: 6102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3898), np.float32(2.5223048))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(fgsm_ds, name=\"FGSM + Transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wc70f3bwGTC3",
    "outputId": "83a09be5-136e-425f-81a9-9f23e72c3699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PGD + Transformed Evaluation:\n",
      "  Total Samples: 10000\n",
      "  Accuracy: 0.3863\n",
      "  Loss: 2.4916\n",
      "  Correct Predictions: 3863\n",
      "  Incorrect Predictions: 6137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3863), np.float32(2.4916496))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(pgd_ds, name=\"PGD + Transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8EdvYCsGUjn",
    "outputId": "6cb3cecc-bbb2-4b89-93f9-bf60dbfaceb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepFool + Transformed Evaluation:\n",
      "  Total Samples: 200\n",
      "  Accuracy: 0.1900\n",
      "  Loss: 4.7012\n",
      "  Correct Predictions: 38\n",
      "  Incorrect Predictions: 162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.19), np.float32(4.7012343))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_on_dataset(deepfool_ds, name=\"DeepFool + Transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxSk76D4G3Qe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
